{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"getting_started.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN6M0a13RRfgC41zPEOqfpy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rfrkm9NojHQy","colab_type":"text"},"source":["# Getting Started with Spark Standalone cluster\n","Before you start the test, make sure you run all the initial steps to setup your Spark standalone cluster.\n","\n","## Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"RYzZ4M2Ri4Js","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"cd58b972-dc9b-41fa-d19a-ab46f8e12481","executionInfo":{"status":"ok","timestamp":1584583867554,"user_tz":180,"elapsed":70212,"user":{"displayName":"Patricio Valle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrDDCf24Y19OUU8JBf6iNXODjOizKd5uahHJO68w=s64","userId":"11751796994187415762"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Su_4ZKOOjyv7","colab_type":"text"},"source":["## Installing Spark\n","Once you’ve got a Colab notebook up, to get Spark running you have to run the following block of code (I know it’s not my fault, but I apologize for how ugly it is)."]},{"cell_type":"code","metadata":{"id":"92ITws9XkSTm","colab_type":"code","colab":{}},"source":["%%bash\n","apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","if [[ ! -d spark-2.4.5-bin-hadoop2.7 ]]; then \n","  echo \"Spark hasn't been installed, Downloading and installing!\"\n","  wget -q https://downloads.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","  tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","  rm -f spark-2.4.5-bin-hadoop2.7.tgz\n","fi\n","pip install -q findspark"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ci92Wj1orCfW","colab_type":"code","colab":{}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"  \n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n","import findspark\n","findspark.init()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2TBb5NwLo5Iw","colab_type":"text"},"source":["## Configuring a SparkSession\n","The entry point to using Spark SQL is an object called SparkSession. It initiates a Spark Application which all the code for that Session will run on."]},{"cell_type":"code","metadata":{"id":"Z2nplOPomTC6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"outputId":"face3dcb-059c-42f9-d6c2-f745fec221f5","executionInfo":{"status":"ok","timestamp":1584585886645,"user_tz":180,"elapsed":928,"user":{"displayName":"Patricio Valle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgrDDCf24Y19OUU8JBf6iNXODjOizKd5uahHJO68w=s64","userId":"11751796994187415762"}}},"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder \\\n","    .master(\"local[*]\") \\\n","    .appName(\"DA_Academy_Spark_Evaluation\") \\\n","    .getOrCreate()\n","sc = spark.sparkContext\n","sc"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://c57bad18f90a:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.5</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>DA_Academy_Spark_Evaluation</code></dd>\n","            </dl>\n","        </div>\n","        "],"text/plain":["<SparkContext master=local[*] appName=DA_Academy_Spark_Evaluation>"]},"metadata":{"tags":[]},"execution_count":27}]}]}